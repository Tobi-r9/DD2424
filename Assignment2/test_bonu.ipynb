{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd09ec957caba7ae6ccc97a7fb0804bf14cbdb1f70a4904cd45a06dd27fe16a3b19",
   "display_name": "Python 3.7.6 64-bit ('tensorflow': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utilis as u\n",
    "import importlib\n",
    "import model_bonus as m \n",
    "import mlp as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/data_batch_1'\n",
    "X_train, y_train,Y_train = u.load_data(filename, reshape=False, clipping=True)\n",
    "meanX = np.mean(X_train,axis=1)\n",
    "stdX = np.std(X_train,axis=1)\n",
    "X_train = (X_train-meanX.reshape((len(meanX),1)))/stdX.reshape((len(stdX),1))\n",
    "\n",
    "filename = '/data_batch_2'\n",
    "X_val, y_val,Y_val = u.load_data(filename, reshape=False, clipping=True)\n",
    "X_val = (X_val-meanX.reshape((len(meanX),1)))/stdX.reshape((len(stdX),1))\n",
    "\n",
    "filename = '/test_batch'\n",
    "X_test, y_test,Y_test = u.load_data(filename, reshape=False, clipping=True)\n",
    "X_test = (X_test-meanX.reshape((len(meanX),1)))/stdX.reshape((len(stdX),1))\n",
    "\n",
    "data = {'X_train':X_train, 'Y_train':Y_train, 'y_train':y_train,'X_val':X_val, 'Y_val':Y_val, 'y_val':y_val}"
   ]
  },
  {
   "source": [
    "# test data augmentation with two different settings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [04:17<00:00, 12.87s/it]\n",
      "100%|██████████| 20/20 [03:41<00:00, 11.06s/it]\n",
      "100%|██████████| 20/20 [04:21<00:00, 13.06s/it]\n",
      "100%|██████████| 20/20 [03:31<00:00, 10.56s/it]\n",
      "100%|██████████| 20/20 [04:22<00:00, 13.12s/it]\n",
      "100%|██████████| 20/20 [03:38<00:00, 10.94s/it]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(m)\n",
    "ns = 2*np.floor(X_train.shape[1]/100)\n",
    "settings = [{\"epochs\":10, \"n_batch\":100, \"eta_min\":0.001,'eta_max':1e-1, 'ns':ns, 'n_cycles':5, 'freq':10,'lambda':0},{\"epochs\":10, \"n_batch\":100, \"eta_min\":0.001,'eta_max':1e-1, 'ns':ns, 'n_cycles':5, 'freq':10,'lambda':0.01},{\"epochs\":10, \"n_batch\":100, \"eta_min\":0.001,'eta_max':1e-1, 'ns':ns, 'n_cycles':5, 'freq':10,'lambda':0.1}]\n",
    "for GDparams in settings:\n",
    "    mlp = m.MLP(lambda_=GDparams['lambda'])  \n",
    "    mlp.cyclicLearning(data, GDparams, 'data_augmentation', False,True, False, True)\n",
    "    mlp = m.MLP(lambda_=GDparams['lambda'])  \n",
    "    mlp.cyclicLearning(data, GDparams, 'no_data_augmentation', False,False, False, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [03:17<00:00,  9.89s/it]\n",
      "100%|██████████| 20/20 [03:26<00:00, 10.30s/it]\n",
      "100%|██████████| 20/20 [03:27<00:00, 10.38s/it]\n",
      "100%|██████████| 20/20 [02:59<00:00,  8.96s/it]\n",
      "100%|██████████| 20/20 [03:02<00:00,  9.14s/it]\n",
      "100%|██████████| 20/20 [02:59<00:00,  8.97s/it]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(m)\n",
    "ns = 2*np.floor(X_train.shape[1]/100)\n",
    "settings = [{\"epochs\":10, \"n_batch\":100, \"eta_min\":0.001,'eta_max':1e-1, 'ns':ns, 'n_cycles':5, 'freq':10,'lambda':0},{\"epochs\":10, \"n_batch\":100, \"eta_min\":0.001,'eta_max':1e-1, 'ns':ns, 'n_cycles':5, 'freq':10,'lambda':0.01},{\"epochs\":10, \"n_batch\":100, \"eta_min\":0.001,'eta_max':1e-1, 'ns':ns, 'n_cycles':5, 'freq':10,'lambda':0.1}]\n",
    "\n",
    "for GDparams in settings:\n",
    "    mlp = m.MLP(lambda_=GDparams['lambda'])  \n",
    "    mlp.cyclicLearning(data, GDparams, 'ensemble_learning', True,False, False, True)\n",
    "    mlp = m.MLP(lambda_=GDparams['lambda'])  \n",
    "    mlp.cyclicLearning(data, GDparams, 'no_ensemble_learning', False,False, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "cost = 1.929311294880992, val_cost = 2.155455674507245,  \n",
      " \t train_acc = 0.4894, val_acc = 0.4044\n",
      "\t Epoch 280.0: train_cost = 1.8271893076984589, val_cost = 2.0775916197076896,  \n",
      " \t train_acc = 0.5191, val_acc = 0.4242\n",
      " 15%|█▌        | 3/20 [00:31<03:05, 10.89s/it]\t Epoch 320.0: train_cost = 1.7617516848788801, val_cost = 2.0352651206959482,  \n",
      " \t train_acc = 0.5413, val_acc = 0.4356\n",
      "\t Epoch 360.0: train_cost = 1.716384214179277, val_cost = 2.010235249361683,  \n",
      " \t train_acc = 0.5603, val_acc = 0.4427\n",
      " 20%|██        | 4/20 [00:39<02:41, 10.12s/it]\t Epoch 0.0: train_cost = 1.6876881245443238, val_cost = 1.9915347972026898,  \n",
      " \t train_acc = 0.5727, val_acc = 0.4491\n",
      "\t Epoch 40.0: train_cost = 1.6854297732131989, val_cost = 1.9958210349098118,  \n",
      " \t train_acc = 0.572, val_acc = 0.447\n",
      "\t Epoch 80.0: train_cost = 1.697201728233789, val_cost = 2.01518458152247,  \n",
      " \t train_acc = 0.562, val_acc = 0.4335\n",
      " 25%|██▌       | 5/20 [00:51<02:36, 10.45s/it]\t Epoch 120.0: train_cost = 1.6915390604344926, val_cost = 2.0275829486811876,  \n",
      " \t train_acc = 0.5652, val_acc = 0.4356\n",
      "\t Epoch 160.0: train_cost = 1.7673551897013047, val_cost = 2.126417670877302,  \n",
      " \t train_acc = 0.5189, val_acc = 0.4065\n",
      " 30%|███       | 6/20 [00:59<02:17,  9.83s/it]\t Epoch 200.0: train_cost = 1.7742760536521145, val_cost = 2.123607170203114,  \n",
      " \t train_acc = 0.5101, val_acc = 0.4026\n",
      "\t Epoch 240.0: train_cost = 1.6463821683537123, val_cost = 2.025524723906095,  \n",
      " \t train_acc = 0.5584, val_acc = 0.4195\n",
      "\t Epoch 280.0: train_cost = 1.578547402070882, val_cost = 1.9753043132924744,  \n",
      " \t train_acc = 0.5755, val_acc = 0.4386\n",
      " 35%|███▌      | 7/20 [01:10<02:13, 10.28s/it]\t Epoch 320.0: train_cost = 1.5056267098030682, val_cost = 1.9362984500387346,  \n",
      " \t train_acc = 0.6074, val_acc = 0.4494\n",
      "\t Epoch 360.0: train_cost = 1.4629641802684374, val_cost = 1.9103219405438063,  \n",
      " \t train_acc = 0.6348, val_acc = 0.4555\n",
      " 40%|████      | 8/20 [01:19<01:56,  9.69s/it]\t Epoch 0.0: train_cost = 1.4384722402396817, val_cost = 1.89448104084451,  \n",
      " \t train_acc = 0.6417, val_acc = 0.4602\n",
      "\t Epoch 40.0: train_cost = 1.443057062561183, val_cost = 1.903987679777742,  \n",
      " \t train_acc = 0.6374, val_acc = 0.4564\n",
      "\t Epoch 80.0: train_cost = 1.454654517557074, val_cost = 1.9297242720029884,  \n",
      " \t train_acc = 0.63, val_acc = 0.4489\n",
      " 45%|████▌     | 9/20 [01:30<01:51, 10.14s/it]\t Epoch 120.0: train_cost = 1.4833773731044044, val_cost = 1.9802845586010647,  \n",
      " \t train_acc = 0.6133, val_acc = 0.4375\n",
      "\t Epoch 160.0: train_cost = 1.5090831176696178, val_cost = 2.0015393770598258,  \n",
      " \t train_acc = 0.5988, val_acc = 0.4245\n",
      " 50%|█████     | 10/20 [01:38<01:36,  9.61s/it]\t Epoch 200.0: train_cost = 1.5848402442756095, val_cost = 2.0856570378157544,  \n",
      " \t train_acc = 0.5669, val_acc = 0.4084\n",
      "\t Epoch 240.0: train_cost = 1.4780824480846668, val_cost = 1.9805297709679344,  \n",
      " \t train_acc = 0.6026, val_acc = 0.431\n",
      "\t Epoch 280.0: train_cost = 1.4116308801001174, val_cost = 1.9326964529466697,  \n",
      " \t train_acc = 0.6308, val_acc = 0.4443\n",
      " 55%|█████▌    | 11/20 [01:49<01:30, 10.10s/it]\t Epoch 320.0: train_cost = 1.3483171915550536, val_cost = 1.9111756086831815,  \n",
      " \t train_acc = 0.6638, val_acc = 0.4504\n",
      "\t Epoch 360.0: train_cost = 1.3093670832191635, val_cost = 1.8917710150751044,  \n",
      " \t train_acc = 0.6817, val_acc = 0.4588\n",
      " 60%|██████    | 12/20 [01:58<01:16,  9.58s/it]\t Epoch 0.0: train_cost = 1.2759111137862025, val_cost = 1.8648775762209802,  \n",
      " \t train_acc = 0.7017, val_acc = 0.4654\n",
      "\t Epoch 40.0: train_cost = 1.2859674019098988, val_cost = 1.8803654381005275,  \n",
      " \t train_acc = 0.6887, val_acc = 0.4642\n",
      "\t Epoch 80.0: train_cost = 1.304020176479641, val_cost = 1.9095807163397904,  \n",
      " \t train_acc = 0.678, val_acc = 0.458\n",
      " 65%|██████▌   | 13/20 [02:09<01:10, 10.09s/it]\t Epoch 120.0: train_cost = 1.3054004485742052, val_cost = 1.9340572392901756,  \n",
      " \t train_acc = 0.6796, val_acc = 0.4516\n",
      "\t Epoch 160.0: train_cost = 1.9066588676549534, val_cost = 2.5015520013222257,  \n",
      " \t train_acc = 0.513, val_acc = 0.3646\n",
      " 70%|███████   | 14/20 [02:17<00:57,  9.56s/it]\t Epoch 200.0: train_cost = 1.8576181301680668, val_cost = 2.453498974682763,  \n",
      " \t train_acc = 0.5167, val_acc = 0.3817\n",
      "\t Epoch 240.0: train_cost = 1.4155954821599845, val_cost = 2.0228285073988665,  \n",
      " \t train_acc = 0.6177, val_acc = 0.4283\n",
      "\t Epoch 280.0: train_cost = 1.3408435586822884, val_cost = 1.9756925829235208,  \n",
      " \t train_acc = 0.6494, val_acc = 0.4425\n",
      " 75%|███████▌  | 15/20 [02:29<00:50, 10.06s/it]\t Epoch 320.0: train_cost = 1.235855221481374, val_cost = 1.8902880249082963,  \n",
      " \t train_acc = 0.707, val_acc = 0.4595\n",
      "\t Epoch 360.0: train_cost = 1.1936104210670202, val_cost = 1.8725500798604695,  \n",
      " \t train_acc = 0.7326, val_acc = 0.4651\n",
      " 80%|████████  | 16/20 [02:37<00:38,  9.55s/it]\t Epoch 0.0: train_cost = 1.1684890280865259, val_cost = 1.860803358265708,  \n",
      " \t train_acc = 0.7421, val_acc = 0.4688\n",
      "\t Epoch 40.0: train_cost = 1.1752969231319716, val_cost = 1.873106975885963,  \n",
      " \t train_acc = 0.7368, val_acc = 0.4648\n",
      "\t Epoch 80.0: train_cost = 1.215458970636483, val_cost = 1.925698621791534,  \n",
      " \t train_acc = 0.7089, val_acc = 0.4556\n",
      " 85%|████████▌ | 17/20 [02:48<00:30, 10.03s/it]\t Epoch 120.0: train_cost = 1.2552762684981458, val_cost = 1.9704357304548878,  \n",
      " \t train_acc = 0.6886, val_acc = 0.4465\n",
      "\t Epoch 160.0: train_cost = 1.4325586823406238, val_cost = 2.1623858317343267,  \n",
      " \t train_acc = 0.618, val_acc = 0.4083\n",
      " 90%|█████████ | 18/20 [02:56<00:19,  9.50s/it]\t Epoch 200.0: train_cost = 1.9723171333303688, val_cost = 2.6352192968224357,  \n",
      " \t train_acc = 0.4865, val_acc = 0.3471\n",
      "\t Epoch 240.0: train_cost = 1.317251648750776, val_cost = 2.005899019043193,  \n",
      " \t train_acc = 0.6573, val_acc = 0.4407\n",
      "\t Epoch 280.0: train_cost = 1.2555234883313229, val_cost = 1.9652677373448848,  \n",
      " \t train_acc = 0.6843, val_acc = 0.4421\n",
      " 95%|█████████▌| 19/20 [03:08<00:10, 10.02s/it]\t Epoch 320.0: train_cost = 1.1702444267323875, val_cost = 1.9219818639729254,  \n",
      " \t train_acc = 0.7336, val_acc = 0.4589\n",
      "\t Epoch 360.0: train_cost = 1.1224175507106964, val_cost = 1.8865812204241434,  \n",
      " \t train_acc = 0.7608, val_acc = 0.4677\n",
      "100%|██████████| 20/20 [03:16<00:00,  9.82s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\t Epoch 0: train_cost = 4.658451649396284, val_cost = 4.660251421455163,  \n",
      " \t train_acc = 0.094, val_acc = 0.0959\n",
      "\t Epoch 40.0: train_cost = 3.967487769655403, val_cost = 4.019579958836462,  \n",
      " \t train_acc = 0.3276, val_acc = 0.3025\n",
      "\t Epoch 80.0: train_cost = 3.6958089338538267, val_cost = 3.8047456409354035,  \n",
      " \t train_acc = 0.397, val_acc = 0.3524\n",
      "  5%|▌         | 1/20 [00:13<04:25, 13.95s/it]\t Epoch 120.0: train_cost = 3.5103220599079283, val_cost = 3.652124476449583,  \n",
      " \t train_acc = 0.4135, val_acc = 0.3605\n",
      "\t Epoch 160.0: train_cost = 3.2867188361321795, val_cost = 3.471853697893464,  \n",
      " \t train_acc = 0.4266, val_acc = 0.3631\n",
      " 10%|█         | 2/20 [00:24<03:51, 12.88s/it]\t Epoch 200.0: train_cost = 3.1242791894373347, val_cost = 3.344300334070646,  \n",
      " \t train_acc = 0.4292, val_acc = 0.3605\n",
      "\t Epoch 240.0: train_cost = 2.7428365642079893, val_cost = 2.9632530416808107,  \n",
      " \t train_acc = 0.4982, val_acc = 0.4056\n",
      "\t Epoch 280.0: train_cost = 2.5515033675984604, val_cost = 2.796825019571845,  \n",
      " \t train_acc = 0.5222, val_acc = 0.4306\n",
      " 15%|█▌        | 3/20 [00:38<03:43, 13.14s/it]\t Epoch 320.0: train_cost = 2.4299220389704774, val_cost = 2.693029077122362,  \n",
      " \t train_acc = 0.5442, val_acc = 0.4392\n",
      "\t Epoch 360.0: train_cost = 2.349619113181695, val_cost = 2.6287663314551635,  \n",
      " \t train_acc = 0.5678, val_acc = 0.4512\n",
      " 20%|██        | 4/20 [00:48<03:16, 12.30s/it]\t Epoch 0.0: train_cost = 2.3101726419252087, val_cost = 2.5987084350267815,  \n",
      " \t train_acc = 0.5814, val_acc = 0.4544\n",
      "\t Epoch 40.0: train_cost = 2.297313297461142, val_cost = 2.591315794380543,  \n",
      " \t train_acc = 0.5788, val_acc = 0.4533\n",
      "\t Epoch 80.0: train_cost = 2.276353579680711, val_cost = 2.576429442329988,  \n",
      " \t train_acc = 0.5661, val_acc = 0.441\n",
      " 25%|██▌       | 5/20 [01:02<03:11, 12.75s/it]\t Epoch 120.0: train_cost = 2.2346060996532504, val_cost = 2.548437003883213,  \n",
      " \t train_acc = 0.5635, val_acc = 0.4313\n",
      "\t Epoch 160.0: train_cost = 2.28239314554848, val_cost = 2.6029610922450543,  \n",
      " \t train_acc = 0.5004, val_acc = 0.3916\n",
      " 30%|███       | 6/20 [01:12<02:48, 12.04s/it]\t Epoch 200.0: train_cost = 2.1576049713733028, val_cost = 2.4732208879223796,  \n",
      " \t train_acc = 0.5141, val_acc = 0.4158\n",
      "\t Epoch 240.0: train_cost = 1.9915189142546788, val_cost = 2.324897374677505,  \n",
      " \t train_acc = 0.5594, val_acc = 0.4321\n",
      "\t Epoch 280.0: train_cost = 1.8902922382229557, val_cost = 2.2411842242366484,  \n",
      " \t train_acc = 0.5841, val_acc = 0.4454\n",
      " 35%|███▌      | 7/20 [01:26<02:42, 12.53s/it]\t Epoch 320.0: train_cost = 1.8074237415866667, val_cost = 2.189687608841945,  \n",
      " \t train_acc = 0.6041, val_acc = 0.4559\n",
      "\t Epoch 360.0: train_cost = 1.75633790619068, val_cost = 2.152710429631801,  \n",
      " \t train_acc = 0.6317, val_acc = 0.4663\n",
      " 40%|████      | 8/20 [01:36<02:22, 11.89s/it]\t Epoch 0.0: train_cost = 1.7279735584103415, val_cost = 2.1307131426751558,  \n",
      " \t train_acc = 0.645, val_acc = 0.4712\n",
      "\t Epoch 40.0: train_cost = 1.7280181653681894, val_cost = 2.131671258994332,  \n",
      " \t train_acc = 0.6371, val_acc = 0.466\n",
      "\t Epoch 80.0: train_cost = 1.7337574137104865, val_cost = 2.1487096383160065,  \n",
      " \t train_acc = 0.6226, val_acc = 0.4598\n",
      " 45%|████▌     | 9/20 [01:50<02:16, 12.43s/it]\t Epoch 120.0: train_cost = 1.7345476450195072, val_cost = 2.1666511916778637,  \n",
      " \t train_acc = 0.6089, val_acc = 0.4463\n",
      "\t Epoch 160.0: train_cost = 1.7520873139813196, val_cost = 2.1689891330058444,  \n",
      " \t train_acc = 0.5836, val_acc = 0.4278\n",
      " 50%|█████     | 10/20 [02:01<01:59, 12.00s/it]\t Epoch 200.0: train_cost = 1.7836195006294502, val_cost = 2.201861957904176,  \n",
      " \t train_acc = 0.5586, val_acc = 0.4153\n",
      "\t Epoch 240.0: train_cost = 1.7163487262449015, val_cost = 2.1361954331887576,  \n",
      " \t train_acc = 0.5716, val_acc = 0.4206\n",
      "\t Epoch 280.0: train_cost = 1.5883734225225812, val_cost = 2.0206900621843906,  \n",
      " \t train_acc = 0.6227, val_acc = 0.4524\n",
      " 55%|█████▌    | 11/20 [02:15<01:52, 12.51s/it]\t Epoch 320.0: train_cost = 1.5374934029001084, val_cost = 2.002985880438954,  \n",
      " \t train_acc = 0.6457, val_acc = 0.455\n",
      "\t Epoch 360.0: train_cost = 1.4919997478627152, val_cost = 1.9702046358921532,  \n",
      " \t train_acc = 0.6631, val_acc = 0.4725\n",
      " 60%|██████    | 12/20 [02:25<01:34, 11.86s/it]\t Epoch 0.0: train_cost = 1.4603495111135611, val_cost = 1.943566144539934,  \n",
      " \t train_acc = 0.6891, val_acc = 0.4768\n",
      "\t Epoch 40.0: train_cost = 1.4674509599191161, val_cost = 1.9562876986229756,  \n",
      " \t train_acc = 0.6717, val_acc = 0.4747\n",
      "\t Epoch 80.0: train_cost = 1.4830857414480598, val_cost = 1.979775271393959,  \n",
      " \t train_acc = 0.6667, val_acc = 0.4663\n",
      " 65%|██████▌   | 13/20 [02:39<01:27, 12.43s/it]\t Epoch 120.0: train_cost = 1.4796995333089764, val_cost = 1.9915788288957381,  \n",
      " \t train_acc = 0.6641, val_acc = 0.4566\n",
      "\t Epoch 160.0: train_cost = 1.846316620779176, val_cost = 2.3327433153638926,  \n",
      " \t train_acc = 0.5297, val_acc = 0.3885\n",
      " 70%|███████   | 14/20 [02:49<01:10, 11.82s/it]\t Epoch 200.0: train_cost = 1.9670699467372328, val_cost = 2.42614378023585,  \n",
      " \t train_acc = 0.5053, val_acc = 0.3796\n",
      "\t Epoch 240.0: train_cost = 1.5459760064768098, val_cost = 2.0143141758829137,  \n",
      " \t train_acc = 0.6059, val_acc = 0.4438\n",
      "\t Epoch 280.0: train_cost = 1.4973517280689927, val_cost = 1.9969812038561776,  \n",
      " \t train_acc = 0.622, val_acc = 0.4428\n",
      " 75%|███████▌  | 15/20 [03:03<01:02, 12.45s/it]\t Epoch 320.0: train_cost = 1.3936260809349856, val_cost = 1.9022324635267367,  \n",
      " \t train_acc = 0.6839, val_acc = 0.4694\n",
      "\t Epoch 360.0: train_cost = 1.3558869702906649, val_cost = 1.8912328321075575,  \n",
      " \t train_acc = 0.7066, val_acc = 0.4794\n",
      " 80%|████████  | 16/20 [03:14<00:47, 11.90s/it]\t Epoch 0.0: train_cost = 1.3318985189926598, val_cost = 1.8766503334693447,  \n",
      " \t train_acc = 0.7165, val_acc = 0.4797\n",
      "\t Epoch 40.0: train_cost = 1.3368362498103858, val_cost = 1.8848598750787593,  \n",
      " \t train_acc = 0.7116, val_acc = 0.4803\n",
      "\t Epoch 80.0: train_cost = 1.375812503825124, val_cost = 1.931628211726202,  \n",
      " \t train_acc = 0.68, val_acc = 0.465\n",
      " 85%|████████▌ | 17/20 [03:28<00:37, 12.52s/it]\t Epoch 120.0: train_cost = 1.4370139937301663, val_cost = 1.9945608084122852,  \n",
      " \t train_acc = 0.6493, val_acc = 0.446\n",
      "\t Epoch 160.0: train_cost = 1.6294791937738107, val_cost = 2.1921908190184176,  \n",
      " \t train_acc = 0.581, val_acc = 0.4011\n",
      " 90%|█████████ | 18/20 [03:38<00:23, 11.88s/it]\t Epoch 200.0: train_cost = 1.8682449016926683, val_cost = 2.3581404871618443,  \n",
      " \t train_acc = 0.517, val_acc = 0.3813\n",
      "\t Epoch 240.0: train_cost = 1.4718860865810661, val_cost = 1.991816861321481,  \n",
      " \t train_acc = 0.6244, val_acc = 0.4446\n",
      "\t Epoch 280.0: train_cost = 1.4152008738673236, val_cost = 1.9462179048129615,  \n",
      " \t train_acc = 0.6515, val_acc = 0.4558\n",
      " 95%|█████████▌| 19/20 [03:52<00:12, 12.43s/it]\t Epoch 320.0: train_cost = 1.3341255435738946, val_cost = 1.9007964269677333,  \n",
      " \t train_acc = 0.7028, val_acc = 0.4705\n",
      "\t Epoch 360.0: train_cost = 1.2952295065297328, val_cost = 1.868303947544181,  \n",
      " \t train_acc = 0.7242, val_acc = 0.4788\n",
      "100%|██████████| 20/20 [04:02<00:00, 12.13s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\t Epoch 0: train_cost = 43.50175944789628, val_cost = 43.49844316093078,  \n",
      " \t train_acc = 0.0964, val_acc = 0.1006\n",
      "\t Epoch 40.0: train_cost = 36.50965827504674, val_cost = 36.54701860870612,  \n",
      " \t train_acc = 0.3138, val_acc = 0.3013\n",
      "\t Epoch 80.0: train_cost = 23.051050481211234, val_cost = 23.126832898173177,  \n",
      " \t train_acc = 0.391, val_acc = 0.3496\n",
      "  5%|▌         | 1/20 [00:19<06:05, 19.24s/it]\t Epoch 120.0: train_cost = 11.360181575056473, val_cost = 11.427251806993574,  \n",
      " \t train_acc = 0.4061, val_acc = 0.3714\n",
      "\t Epoch 160.0: train_cost = 5.036736197290226, val_cost = 5.094545463257536,  \n",
      " \t train_acc = 0.3945, val_acc = 0.3635\n",
      " 10%|█         | 2/20 [00:33<05:21, 17.88s/it]\t Epoch 200.0: train_cost = 2.727233062553913, val_cost = 2.7853734797436758,  \n",
      " \t train_acc = 0.3759, val_acc = 0.3453\n",
      "\t Epoch 240.0: train_cost = 2.171393415546943, val_cost = 2.2190632527272998,  \n",
      " \t train_acc = 0.3856, val_acc = 0.3596\n",
      "\t Epoch 280.0: train_cost = 2.04782716965809, val_cost = 2.0980658847854623,  \n",
      " \t train_acc = 0.3821, val_acc = 0.3593\n",
      " 15%|█▌        | 3/20 [00:52<05:09, 18.22s/it]\t Epoch 320.0: train_cost = 2.0058805845351175, val_cost = 2.05558923820311,  \n",
      " \t train_acc = 0.3933, val_acc = 0.3677\n",
      "\t Epoch 360.0: train_cost = 1.9914660849854195, val_cost = 2.0402693879879266,  \n",
      " \t train_acc = 0.4005, val_acc = 0.3742\n",
      " 20%|██        | 4/20 [01:07<04:35, 17.20s/it]\t Epoch 0.0: train_cost = 1.9827352972015144, val_cost = 2.031991367508092,  \n",
      " \t train_acc = 0.4047, val_acc = 0.3787\n",
      "\t Epoch 40.0: train_cost = 1.9820864743199598, val_cost = 2.0331458051694944,  \n",
      " \t train_acc = 0.4046, val_acc = 0.3757\n",
      "\t Epoch 80.0: train_cost = 1.9874183274692179, val_cost = 2.0375545132779784,  \n",
      " \t train_acc = 0.3901, val_acc = 0.3702\n",
      " 25%|██▌       | 5/20 [01:26<04:26, 17.76s/it]\t Epoch 120.0: train_cost = 1.9947077842677572, val_cost = 2.0450394794070945,  \n",
      " \t train_acc = 0.3854, val_acc = 0.3605\n",
      "\t Epoch 160.0: train_cost = 2.0205593202136103, val_cost = 2.0659410206500444,  \n",
      " \t train_acc = 0.3662, val_acc = 0.3454\n",
      " 30%|███       | 6/20 [01:41<03:55, 16.81s/it]\t Epoch 200.0: train_cost = 2.0043818676372704, val_cost = 2.0536585629131747,  \n",
      " \t train_acc = 0.3825, val_acc = 0.3533\n",
      "\t Epoch 240.0: train_cost = 1.9931728226183658, val_cost = 2.0461869593513327,  \n",
      " \t train_acc = 0.3789, val_acc = 0.3484\n",
      "\t Epoch 280.0: train_cost = 1.9803154934784077, val_cost = 2.0288209134667166,  \n",
      " \t train_acc = 0.3941, val_acc = 0.3688\n",
      " 35%|███▌      | 7/20 [02:00<03:46, 17.41s/it]\t Epoch 320.0: train_cost = 1.975988898455567, val_cost = 2.0252218452938107,  \n",
      " \t train_acc = 0.3931, val_acc = 0.3682\n",
      "\t Epoch 360.0: train_cost = 1.968018486369465, val_cost = 2.0205360482570516,  \n",
      " \t train_acc = 0.3969, val_acc = 0.3706\n",
      " 40%|████      | 8/20 [02:14<03:18, 16.57s/it]\t Epoch 0.0: train_cost = 1.963031131388619, val_cost = 2.0145375094674978,  \n",
      " \t train_acc = 0.405, val_acc = 0.3753\n",
      "\t Epoch 40.0: train_cost = 1.965137909582793, val_cost = 2.0166184322910254,  \n",
      " \t train_acc = 0.4013, val_acc = 0.3717\n",
      "\t Epoch 80.0: train_cost = 1.972495379685234, val_cost = 2.0257913515953496,  \n",
      " \t train_acc = 0.3989, val_acc = 0.3698\n",
      " 45%|████▌     | 9/20 [02:34<03:11, 17.38s/it]\t Epoch 120.0: train_cost = 1.9775218363658127, val_cost = 2.027804913739307,  \n",
      " \t train_acc = 0.3992, val_acc = 0.3749\n",
      "\t Epoch 160.0: train_cost = 1.99195462892324, val_cost = 2.040648219254713,  \n",
      " \t train_acc = 0.3955, val_acc = 0.362\n",
      " 50%|█████     | 10/20 [02:48<02:45, 16.56s/it]\t Epoch 200.0: train_cost = 2.0024162391513074, val_cost = 2.052992583996458,  \n",
      " \t train_acc = 0.3862, val_acc = 0.3488\n",
      "\t Epoch 240.0: train_cost = 1.9962456968880182, val_cost = 2.0415689700277495,  \n",
      " \t train_acc = 0.3808, val_acc = 0.3576\n",
      "\t Epoch 280.0: train_cost = 1.9787232988894903, val_cost = 2.0291258146529945,  \n",
      " \t train_acc = 0.389, val_acc = 0.3583\n",
      " 55%|█████▌    | 11/20 [03:08<02:36, 17.37s/it]\t Epoch 320.0: train_cost = 1.9773301366141989, val_cost = 2.028151194636067,  \n",
      " \t train_acc = 0.3951, val_acc = 0.3618\n",
      "\t Epoch 360.0: train_cost = 1.9694814256030138, val_cost = 2.022854029555719,  \n",
      " \t train_acc = 0.3955, val_acc = 0.367\n",
      " 60%|██████    | 12/20 [03:22<02:12, 16.56s/it]\t Epoch 0.0: train_cost = 1.9599156960119604, val_cost = 2.01126598058107,  \n",
      " \t train_acc = 0.4068, val_acc = 0.3783\n",
      "\t Epoch 40.0: train_cost = 1.9638588880134185, val_cost = 2.0149556803761755,  \n",
      " \t train_acc = 0.4025, val_acc = 0.3727\n",
      "\t Epoch 80.0: train_cost = 1.9726161598371732, val_cost = 2.0265357606968286,  \n",
      " \t train_acc = 0.4006, val_acc = 0.3743\n",
      " 65%|██████▌   | 13/20 [03:41<02:01, 17.29s/it]\t Epoch 120.0: train_cost = 1.975214823644769, val_cost = 2.0281471033006278,  \n",
      " \t train_acc = 0.3999, val_acc = 0.3694\n",
      "\t Epoch 160.0: train_cost = 2.0005111027771854, val_cost = 2.0441795291457865,  \n",
      " \t train_acc = 0.3838, val_acc = 0.3608\n",
      " 70%|███████   | 14/20 [03:56<01:39, 16.52s/it]\t Epoch 200.0: train_cost = 2.039453385876848, val_cost = 2.0864050804721685,  \n",
      " \t train_acc = 0.3545, val_acc = 0.3363\n",
      "\t Epoch 240.0: train_cost = 2.0084434771858035, val_cost = 2.049546153579497,  \n",
      " \t train_acc = 0.3752, val_acc = 0.3519\n",
      "\t Epoch 280.0: train_cost = 1.9708616329275948, val_cost = 2.0206498974366864,  \n",
      " \t train_acc = 0.3881, val_acc = 0.3653\n",
      " 75%|███████▌  | 15/20 [04:15<01:26, 17.29s/it]\t Epoch 320.0: train_cost = 1.9697319351086944, val_cost = 2.018453180028807,  \n",
      " \t train_acc = 0.3926, val_acc = 0.3651\n",
      "\t Epoch 360.0: train_cost = 1.9612330338844692, val_cost = 2.0132543542791503,  \n",
      " \t train_acc = 0.4023, val_acc = 0.3743\n",
      " 80%|████████  | 16/20 [04:30<01:05, 16.50s/it]\t Epoch 0.0: train_cost = 1.9569542902581574, val_cost = 2.0087085966195404,  \n",
      " \t train_acc = 0.411, val_acc = 0.3778\n",
      "\t Epoch 40.0: train_cost = 1.9581048765274638, val_cost = 2.0096156331635746,  \n",
      " \t train_acc = 0.4089, val_acc = 0.3791\n",
      "\t Epoch 80.0: train_cost = 1.963097346963693, val_cost = 2.0150500050729994,  \n",
      " \t train_acc = 0.4013, val_acc = 0.3677\n",
      " 85%|████████▌ | 17/20 [04:49<00:51, 17.27s/it]\t Epoch 120.0: train_cost = 1.9815245815554743, val_cost = 2.0325925731591297,  \n",
      " \t train_acc = 0.3819, val_acc = 0.3593\n",
      "\t Epoch 160.0: train_cost = 2.0104183504500917, val_cost = 2.0630777048349165,  \n",
      " \t train_acc = 0.3736, val_acc = 0.3457\n",
      " 90%|█████████ | 18/20 [05:03<00:32, 16.49s/it]\t Epoch 200.0: train_cost = 1.9993431154431307, val_cost = 2.0475312646528354,  \n",
      " \t train_acc = 0.3753, val_acc = 0.3459\n",
      "\t Epoch 240.0: train_cost = 1.9843136080748685, val_cost = 2.033210690999314,  \n",
      " \t train_acc = 0.3883, val_acc = 0.3578\n",
      "\t Epoch 280.0: train_cost = 1.971716695291784, val_cost = 2.0186347509225064,  \n",
      " \t train_acc = 0.3965, val_acc = 0.3668\n",
      " 95%|█████████▌| 19/20 [05:23<00:17, 17.30s/it]\t Epoch 320.0: train_cost = 1.9709433018543285, val_cost = 2.0264266212545987,  \n",
      " \t train_acc = 0.3856, val_acc = 0.3571\n",
      "\t Epoch 360.0: train_cost = 1.9595287086525015, val_cost = 2.0086874510057893,  \n",
      " \t train_acc = 0.4091, val_acc = 0.3772\n",
      "100%|██████████| 20/20 [05:37<00:00, 16.89s/it]\n"
     ]
    }
   ],
   "source": [
    "settings = [(0.001,50),(0.005,100),(0.01,200),(0.1,400)]\n",
    "GDparams = {\"epochs\":10, \"n_batch\":100, \"eta_min\":0.001,'eta_max':1e-1, 'ns':ns, 'n_cycles':5, 'freq':10,'lambda':0.01}\n",
    "for setting in settings:\n",
    "    lambda_ = setting[0] \n",
    "    d = setting[1]\n",
    "    dimensions = [3072,d,10]\n",
    "    mlp = m.MLP(lambda_=lambda_,dimensions=dimensions)  \n",
    "    mlp.cyclicLearning(data, GDparams, 'test_hidden_units', False,False, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}