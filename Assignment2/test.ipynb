{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd09ec957caba7ae6ccc97a7fb0804bf14cbdb1f70a4904cd45a06dd27fe16a3b19",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utilis as u\n",
    "import importlib\n",
    "import model as m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K, d, n = 10, 3072, 1000\n",
    "\n",
    "filename = '/data_batch_1'\n",
    "X_train, y_train,Y_train = u.load_data(filename, reshape=False, clipping=True)\n",
    "meanX = np.mean(X_train,axis=1)\n",
    "stdX = np.std(X_train,axis=1)\n",
    "X_train = (X_train-meanX.reshape((len(meanX),1)))/stdX.reshape((len(stdX),1))\n",
    "\n",
    "filename = '/data_batch_2'\n",
    "X_val, y_val,Y_val = u.load_data(filename, reshape=False, clipping=True)\n",
    "X_val = (X_val-meanX.reshape((len(meanX),1)))/stdX.reshape((len(stdX),1))\n",
    "\n",
    "filename = '/data_batch_3'\n",
    "X_test, y_test,Y_test = u.load_data(filename, reshape=False, clipping=True)\n",
    "X_test = (X_test-meanX.reshape((len(meanX),1)))/stdX.reshape((len(stdX),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'X_train':X_train, 'Y_train':Y_train, 'y_train':y_train,'X_val':X_val, 'Y_val':Y_val, 'y_val':y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\t Epoch 0: train_loss = 2.4233004516843932, val_loss = 2.41977845104279,  \n",
      " \t train_acc = 0.1028, val_acc = 0.1055\n",
      " 10%|█         | 1/10 [00:04<00:37,  4.20s/it]\t Epoch 100: train_loss = 1.9253180551081128, val_loss = 1.9782084021915387,  \n",
      " \t train_acc = 0.3255, val_acc = 0.3018\n",
      " 20%|██        | 2/10 [00:08<00:33,  4.16s/it]\t Epoch 200: train_loss = 1.7022204262902483, val_loss = 1.8181302298479811,  \n",
      " \t train_acc = 0.4079, val_acc = 0.3631\n",
      " 30%|███       | 3/10 [00:12<00:29,  4.16s/it]\t Epoch 300: train_loss = 1.5806244128061768, val_loss = 1.7598023311295459,  \n",
      " \t train_acc = 0.4509, val_acc = 0.3872\n",
      " 40%|████      | 4/10 [00:16<00:24,  4.08s/it]\t Epoch 400: train_loss = 1.5260190292799583, val_loss = 1.7624841891712513,  \n",
      " \t train_acc = 0.4665, val_acc = 0.3962\n",
      " 50%|█████     | 5/10 [00:20<00:20,  4.02s/it]\t Epoch 500: train_loss = 1.4406359761757075, val_loss = 1.73365340507046,  \n",
      " \t train_acc = 0.5024, val_acc = 0.4096\n",
      " 60%|██████    | 6/10 [00:24<00:16,  4.05s/it]\t Epoch 600: train_loss = 1.3390365886728781, val_loss = 1.6900521784362572,  \n",
      " \t train_acc = 0.5423, val_acc = 0.4268\n",
      " 70%|███████   | 7/10 [00:29<00:13,  4.35s/it]\t Epoch 700: train_loss = 1.2638606245529334, val_loss = 1.6778529984680306,  \n",
      " \t train_acc = 0.5706, val_acc = 0.4359\n",
      " 80%|████████  | 8/10 [00:35<00:09,  4.74s/it]\t Epoch 800: train_loss = 1.2029654460499613, val_loss = 1.6595704496790638,  \n",
      " \t train_acc = 0.6033, val_acc = 0.437\n",
      " 90%|█████████ | 9/10 [00:39<00:04,  4.76s/it]\t Epoch 900: train_loss = 1.1756263901601123, val_loss = 1.660789300125742,  \n",
      " \t train_acc = 0.6071, val_acc = 0.4356\n",
      "100%|██████████| 10/10 [00:44<00:00,  4.48s/it]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(m)\n",
    "mlp = m.MLP()\n",
    "GD_params = {\"n_batch\":100, \"eta_min\":0.001, 'eta_max':0.05, 'ns':500, 'n_cycles':1, 'freq':10}\n",
    "mlp.cyclicLearning(data, GD_params, 'test_cyclic_learning', True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\t Epoch 0: train_loss = 2.429575599446275, val_loss = 2.4260667079286717,  \n",
      " \t train_acc = 0.1015, val_acc = 0.1043\n",
      " 10%|█         | 1/10 [00:04<00:39,  4.43s/it]\t Epoch 1: train_loss = 2.1722377530693757, val_loss = 2.1860343347670312,  \n",
      " \t train_acc = 0.2141, val_acc = 0.2123\n",
      " 20%|██        | 2/10 [00:09<00:37,  4.71s/it]\t Epoch 2: train_loss = 2.083522398511192, val_loss = 2.107887407643722,  \n",
      " \t train_acc = 0.2543, val_acc = 0.2454\n",
      " 30%|███       | 3/10 [00:14<00:32,  4.69s/it]\t Epoch 3: train_loss = 2.0224570558929607, val_loss = 2.0539571219846073,  \n",
      " \t train_acc = 0.2834, val_acc = 0.267\n",
      " 40%|████      | 4/10 [00:18<00:27,  4.61s/it]\t Epoch 4: train_loss = 1.976261402073833, val_loss = 2.0151068133150765,  \n",
      " \t train_acc = 0.3032, val_acc = 0.2864\n",
      " 50%|█████     | 5/10 [00:23<00:22,  4.52s/it]\t Epoch 5: train_loss = 1.939885992472477, val_loss = 1.985120109740847,  \n",
      " \t train_acc = 0.3197, val_acc = 0.2982\n",
      " 60%|██████    | 6/10 [00:27<00:17,  4.46s/it]\t Epoch 6: train_loss = 1.9102782618130623, val_loss = 1.9615551724878328,  \n",
      " \t train_acc = 0.3319, val_acc = 0.3106\n",
      " 70%|███████   | 7/10 [00:31<00:13,  4.47s/it]\t Epoch 7: train_loss = 1.8849671185932741, val_loss = 1.941729617468237,  \n",
      " \t train_acc = 0.344, val_acc = 0.3197\n",
      " 80%|████████  | 8/10 [00:36<00:08,  4.43s/it]\t Epoch 8: train_loss = 1.862629672678139, val_loss = 1.9239679610772946,  \n",
      " \t train_acc = 0.3518, val_acc = 0.3268\n",
      " 90%|█████████ | 9/10 [00:40<00:04,  4.45s/it]\t Epoch 9: train_loss = 1.8434237906613733, val_loss = 1.9097045140931757,  \n",
      " \t train_acc = 0.3584, val_acc = 0.3319\n",
      "100%|██████████| 10/10 [00:45<00:00,  4.53s/it]\t Epoch 10: train_loss = 1.824881359460654, val_loss = 1.8956240381676583,  \n",
      " \t train_acc = 0.367, val_acc = 0.3372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test network\n",
    "importlib.reload(m)\n",
    "mlp = m.MLP()\n",
    "GD_params = {\"epochs\":10, \"n_batch\":100, \"eta\":0.001}\n",
    "hist = mlp.MiniBatch(data,GD_params,'test_minibatch',True,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:04<00:39,  4.35s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:08<00:35,  4.44s/it]\u001b[Ac:\\Users\\User\\Desktop\\KTH\\DeepL\\Assignments\\DD2424\\Assignment2\\model.py:293: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
      "c:\\Users\\User\\Desktop\\KTH\\DeepL\\Assignments\\DD2424\\Assignment2\\model.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
      "\n",
      " 30%|███       | 3/10 [00:13<00:31,  4.49s/it]\u001b[A\n",
      " 40%|████      | 4/10 [00:18<00:26,  4.50s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [00:22<00:21,  4.34s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [00:26<00:17,  4.25s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [00:30<00:12,  4.18s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [00:34<00:08,  4.12s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:38<00:04,  4.15s/it]\u001b[A\n",
      "100%|██████████| 10/10 [00:43<00:00,  4.38s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:04<00:43,  4.87s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:08<00:36,  4.59s/it]\u001b[A\n",
      " 30%|███       | 3/10 [00:12<00:30,  4.39s/it]\u001b[A\n",
      " 40%|████      | 4/10 [00:16<00:25,  4.26s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [00:20<00:20,  4.20s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [00:24<00:16,  4.13s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [00:28<00:12,  4.07s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [00:32<00:08,  4.04s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:36<00:04,  4.05s/it]\u001b[A\n",
      "100%|██████████| 10/10 [00:40<00:00,  4.08s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:03<00:35,  3.93s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:07<00:31,  3.95s/it]\u001b[A\n",
      " 30%|███       | 3/10 [00:11<00:27,  3.97s/it]\u001b[A\n",
      " 40%|████      | 4/10 [00:15<00:23,  3.98s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [00:19<00:19,  3.97s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [00:23<00:15,  3.96s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [00:27<00:11,  3.97s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [00:31<00:07,  3.98s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:35<00:03,  3.97s/it]\u001b[A\n",
      "100%|██████████| 10/10 [00:39<00:00,  3.97s/it]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(m)\n",
    "GD_params = {\"epochs\":2, \"n_batch\":100, \"eta_min\":0.001,'eta_max':1e-1, 'ns':500, 'n_cycles':1, 'freq':10}\n",
    "search = m.Search(-5, -1,[2,1], 'n_batch',[100],'eta_max',[5e-1])\n",
    "model = search.random_search(data=data,GDparams=GD_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0984"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "model.val_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'test'\n",
    "epochs = 40\n",
    "n_batch = 100\n",
    "eta = 0.001\n",
    "lambda_ = 0\n",
    "seed = 42\n",
    "hist = np.load(f\"Models/hist_{experiment}_{epochs}_{n_batch}_{eta}_{lambda_}_{seed}.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.item()['train_acc'])"
   ]
  }
 ]
}